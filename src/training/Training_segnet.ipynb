{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding=utf-8\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import numpy as np  \n",
    "import keras\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Conv2D,MaxPooling2D,UpSampling2D,BatchNormalization,Reshape,Permute,Activation, Input, Dropout\n",
    "from keras.utils.np_utils import to_categorical  \n",
    "from keras.preprocessing.image import img_to_array  \n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "from keras import regularizers\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from sklearn.preprocessing import LabelEncoder  \n",
    "from PIL import Image\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from osgeo import gdal\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "'''\n",
    "Compatible with tensorflow backend\n",
    "'''\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "#River_net\n",
    "\n",
    "img_w = 512 \n",
    "img_h = 512\n",
    "bands = 8\n",
    "n_label = 2  \n",
    "  \n",
    "classes = [1,255] \n",
    "labelencoder = LabelEncoder()  \n",
    "labelencoder.fit(classes)  \n",
    "        \n",
    "def load_img(path, grayscale=False):\n",
    "    dataset = gdal.Open(path)       #打开文件\n",
    "    im_width = dataset.RasterXSize    #栅格矩阵的列数\n",
    "    im_height = dataset.RasterYSize   #栅格矩阵的行数\n",
    "    im_data = dataset.ReadAsArray(0,0,im_width,im_height) #将数据写成数组，对应栅格矩阵\n",
    "    del dataset #关闭对象，文件dataset\n",
    "    img = np.array(im_data,dtype = im_data.dtype)   # band first\n",
    "    if grayscale==False:\n",
    "        img = np.swapaxes(img,0,1)\n",
    "        img = np.swapaxes(img,1,2)\n",
    "    return img\n",
    "\n",
    "def SegNet():  \n",
    "    model = Sequential()  \n",
    "    #encoder  \n",
    "    model.add(Conv2D(64,(3,3),strides=(1,1),input_shape=(img_w,img_h, 3),padding='same',activation='relu', data_format = 'channels_last', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(64,(3,3),strides=(1,1),padding='same',activation='relu', kernel_regularizer=regularizers.l2(0.01)))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))  \n",
    "    #(128,128)  \n",
    "    model.add(Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))  \n",
    "    #(64,64)  \n",
    "    model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))  \n",
    "    #(32,32)  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))  \n",
    "    #(16,16)  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))  \n",
    "    #(8,8)  \n",
    "    #decoder  \n",
    "    model.add(UpSampling2D(size=(2,2)))  \n",
    "    #(16,16)  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(UpSampling2D(size=(2, 2)))  \n",
    "    #(32,32)  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(UpSampling2D(size=(2, 2)))  \n",
    "    #(64,64)  \n",
    "    model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(UpSampling2D(size=(2, 2)))  \n",
    "    #(128,128)  \n",
    "    model.add(Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(UpSampling2D(size=(2, 2)))  \n",
    "    #(256,256)  \n",
    "    model.add(Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))  \n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(Conv2D(n_label, (1, 1), strides=(1, 1), padding='same', activation='softmax'))  \n",
    "    #model.add(Reshape((n_label,img_w*img_h)))  \n",
    "    #axis=1和axis=2互换位置，等同于np.swapaxes(layer,1,2)  \n",
    "    #model.add(Permute((2,1)))  \n",
    "    #model.add(Activation('softmax'))  \n",
    "    model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])  \n",
    "    model.summary()  \n",
    "    return model\n",
    "\n",
    "filepath ='D:\\\\RiversTraining\\\\TwoClasses\\\\training\\\\'\n",
    "\n",
    "def get_train_val(val_rate = 0.25):\n",
    "    train_url = []    \n",
    "    train_set = []\n",
    "    val_set  = []\n",
    "    for pic in os.listdir(filepath + 'src'):\n",
    "        train_url.append(pic)\n",
    "    random.shuffle(train_url)\n",
    "    total_num = len(train_url)\n",
    "    val_num = int(val_rate * total_num)\n",
    "    for i in range(len(train_url)):\n",
    "        if i < val_num:\n",
    "            val_set.append(train_url[i]) \n",
    "        else:\n",
    "            train_set.append(train_url[i])\n",
    "    return train_set,val_set\n",
    "\n",
    "# data for training  \n",
    "def generateData(batch_size,data=[]):  \n",
    "    #print 'generateData...'\n",
    "    while True:  \n",
    "        train_data = []  \n",
    "        train_label = []  \n",
    "        batch = 0  \n",
    "        for i in (range(len(data))): \n",
    "            url = data[i]\n",
    "            batch += 1 \n",
    "            img = load_img(filepath + 'src\\\\' + url)\n",
    "            img = img_to_array(img) \n",
    "            train_data.append(img)  \n",
    "            label = load_img(filepath + 'label\\\\' + url, grayscale=True)            \n",
    "            label = img_to_array(label).reshape((img_w * img_h,))\n",
    "            train_label.append(label)\n",
    "            if batch % batch_size==0: \n",
    "                train_data = np.array(train_data)  \n",
    "                train_label = np.array(train_label).flatten()                \n",
    "                train_label = labelencoder.transform(train_label)                \n",
    "                train_label = to_categorical(train_label, num_classes=n_label)  \n",
    "                train_label = train_label.reshape((batch_size,img_w, img_h,n_label)) \n",
    "                yield (train_data,train_label)\n",
    "                train_data = []  \n",
    "                train_label = []  \n",
    "                batch = 0  \n",
    " \n",
    "# data for validation \n",
    "def generateValidData(batch_size,data=[]):  \n",
    "    #print 'generateValidData...'\n",
    "    while True:  \n",
    "        valid_data = []  \n",
    "        valid_label = []  \n",
    "        batch = 0  \n",
    "        for i in (range(len(data))):  \n",
    "            url = data[i]\n",
    "            batch += 1  \n",
    "            img = load_img(filepath + 'src\\\\' + url)\n",
    "            img = img_to_array(img)  \n",
    "            valid_data.append(img)  \n",
    "            label = load_img(filepath + 'label\\\\' + url, grayscale=True)\n",
    "            label = img_to_array(label).reshape((img_w * img_h,))  \n",
    "            valid_label.append(label)  \n",
    "            if batch % batch_size==0:  \n",
    "                valid_data = np.array(valid_data)  \n",
    "                valid_label = np.array(valid_label).flatten()  \n",
    "                valid_label = labelencoder.transform(valid_label)  \n",
    "                valid_label = to_categorical(valid_label, num_classes=n_label)  \n",
    "                valid_label = valid_label.reshape((batch_size,img_w, img_h,n_label))\n",
    "                yield (valid_data,valid_label)  \n",
    "                valid_data = []  \n",
    "                valid_label = []  \n",
    "                batch = 0  \n",
    "  \n",
    "def train(): \n",
    "    EPOCHS = 20\n",
    "    BS = 3\n",
    "    model = SegNet()\n",
    "    modelcheck = ModelCheckpoint(filepath + 'img_zeb_tune_4.h5',monitor='val_acc',save_best_only=True,mode='max')  \n",
    "    callable = [modelcheck]  \n",
    "    \n",
    "    train_set,val_set = get_train_val()\n",
    "    train_numb = len(train_set)  \n",
    "    valid_numb = len(val_set)  \n",
    "    print (\"the number of train data is\",train_numb)  \n",
    "    print (\"the number of val data is\",valid_numb)\n",
    "    \n",
    "    H = model.fit_generator(generator=generateData(BS,train_set),steps_per_epoch=train_numb//BS,epochs=EPOCHS,verbose=1,  \n",
    "                    validation_data=generateValidData(BS,val_set),validation_steps=valid_numb//BS, callbacks=callable,max_q_size=1)  \n",
    "    model.save(filepath + 'img_zeb4.h5')\n",
    "    \n",
    "    # plot the training loss and accuracy\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    N = EPOCHS\n",
    "    plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.title(\"Training Loss on ZebNet Satellite Seg\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.savefig(filepath + 'train_zeb_tune4_1.jpg')\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "    plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "    plt.title(\"Training Accuracy on ZebNet Satellite Seg\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.savefig(filepath + 'train_zeb_tune4_2.jpg')\n",
    "    \n",
    "if __name__=='__main__':  \n",
    "    train()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
